
                                     "Machine Learning Assignment"

---

Project:  Predicted variables with"classe"of the training set and then created a report describing
of building model and cross validation. Also used prediction model to predict 20 different test cases.

```{r error= FALSE}
library(knitr)
library(lattice)
library(caret)
library(gbm)
library(rpart)
library(lubridate)
library(randomForest)
library(rattle)
library(dplyr)
library(corrplot)
```
#The training and testing data for this project are available here:

```{r}
dataurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv"

quizurl <- "https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv"

dattr <- read.csv(dataurl)
datts <- read.csv(quizurl)

```
#Partition of dattr data into:
#(70%)training data set for modeling process and
#(30%)testing data set for validations. 

```{r }
intrain <- createDataPartition(dattr$classe, p= 0.7 ,list = FALSE)
train <- dattr[intrain,]
test <- dattr[-intrain,]
```
Both train and test data set have  160 variables

#Cleaning of training data set for further use "nearly-zero-variance" for training data predictors and 
#there ID variables for identifing and eliminating prior to modeling.
 
```{r}
natr <- nearZeroVar(train)

train1 <- train[,-natr]
test1 <-  test[,-natr]

```
# Removing variables that are mostly NA
```{r}
nas <- sapply(train1,function(x)mean(is.na(x)))>0.95

train2 <- train1[,nas== FALSE]
test2 <-  test1[,nas== FALSE]
```
# Training and Testing data set for modeling
```{r}
training <- train2[,8:59]
testing <- test2[,8:59]
```
With the process of cleaning data reduced to 54 variables

# Correlation Analysis with correlation plot( corrplot)
```{r tidy=TRUE}
correlation <- cor(training[,1:51])
corrplot(correlation, type ="lower", method = "color")
```
# Highly correlated variables are shown with dark color in the graph.

Three methods are used for model the regression (the training data set) and 
the best one with higher accuracy will be used for quiz pediction. The methods are 
 1 Decision Tree Model
 2 Random Forest
 3 Generalized Boosted Model
Confusion Matrix is plotted at the end of every analysis for better accuracy of the models

#1) Method : Decision Tree Model
```{r}
mod1 <- train(classe ~.,training, method ="rpart")
```
## Prediction on testing data set
```{r}
pred1  <- predict(mod1, testing)
cnmat1 <- confusionMatrix(pred1, testing$classe)
cnmat1
```
# Plot 
```{r tidy=TRUE}
fancyRpartPlot(mod1$finalModel)
```
#2) Method : Random Forest Model
```{r}
mod2 <- randomForest(classe ~., data=training, ntree= 1000)
```
##Prediction on testing data set
```{r}
pred2 <- predict(mod2, testing)
cnmat2 <- confusionMatrix(pred2, testing$classe)
cnmat2
```
#Plot
```{r tidy= TRUE}
plot(cnmat2$table, col=cnmat2$byclass, main = paste( "Decision Tree - Accuracy =",
                                                     round(cnmat2$overall["Accuracy"],4)))
```
#3)  Generalized Boosted Model
```{r}

controlpr <- trainControl(method ="cv", number =3, verbose = FALSE  )
mod3  <- train(classe~., data = training, method='gbm', trControl = controlpr,verbose= FALSE)
```
A gradient boosted model with multinomial loss function.
150 iterations were performed.
There were 51 predictors of which 51 had non-zero influence.

##Prediction on testing data set
```{r}
pred3  <- predict(mod3, testing)
cnmat3  <- confusionMatrix( pred3, testing$classe)$overall[1]
cnmat3
```
# With 3 different regression models we got different accuracies from each  :  
##1) Decision Tree Model
Accuracy : 0.4856 

##2) Random Forest Model
Accuracy : 0.9961  

##3) Genralized Boosted Model
Accuracy : 0.9658454 

 After getting Accuracies of 3 different regression model we finalize to go with 
 Random Forest.

##Applied Random Forest Machine Learning algorithm to the 20 test cases available in the test data 
##predict in appropriate format to the Course Project Prediction Quiz for automated grading.
```{r}
pred5 <- predict(mod2, datts)
```
## Got result as follows:
```{r}
pred5
``` 


